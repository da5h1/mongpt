# mongpt
Инструкционная языковая модель для монгольского языка.

В рамках данного проекта монгольская языковая модель была обучена на наборе переведенных инструкций. В качестве базовой модели использовалсь mGPT-1.3B-mongol. В качестве датасета с инструкциями я использовал databricks-dolly-15k. Этот датасет был переведен на монгольский язык с помощью трех моделей-автопереводчиков. Я отбирал те переводы, которые достаточно похожи друг на друга. 

Для оптимизации расхода памяти я использовал mixed-presicion. Модель обучалась в течении 15 эпох на видеокарте NVIDIA A100, размер батча - 4, количество батчей - 1882. Тренировочный датасет содержит 7527 примеров, валидационный - 396. В качестве метрики обучения был использован BERTScore, в качестве модели BERT - мультиязычная xlm-roberta-large, эмбеддинги были взяты с 17-го слоя. 

Ниже вы можете видеть метрику обучения каждую эпоху.

![my_plot (1)](https://github.com/user-attachments/assets/6e790bd4-3b07-4676-9491-1fafb0e3cc3f)

Так же я провел подбор параметров генерации на валидационном датасете. Я случайно подбирал параметры в некоторых дискретных границах, пока мне не удалось максимизировать значение метрики. Ниже вы можете видеть оптимальную конфигурацию параметров.

*конфигурация параметров*

Оказалось, очень важно, чтобы длина ответа была ненулевой, так как модель склонна выдавать пустые ответы. Также модель склонна к зацикливанию, так что важно зафиксировать параметр, предотвращающий зацикливание.

Так же были проведены эксперименты с обучением с подводкой. Я явно указал модели следующую инструкцию на монгольском языке: "Напиши ответ для задания. Используй грамотный монгольский язык. Представь, что ты монгольский писатель Сэнгийн Эрдэнэ. Используй кириллицу."

Такой метод позволил увеличить значение метрики на каждой эпохе обучения.

*еще одна картинка с обучением в сравнении с прошлой*

На тестовой выборке модель выдала значение BERTScore - *значение*.

Ниже вы можете видеть примеры самых удачных ответов модели и их перевод, полученный с помощью автопереводчика.

*лучшие результаты*

